
# ============================================================================
# PROMPTS FILE REFERENCE
# ============================================================================

# Reference to prompts configuration file
prompts_config:
  file: "ai-prompts.yaml"
  active_prompt_set: "default"  # Can be overridden to switch prompt sets

# ============================================================================
# UNIFIED PROCESSING CONFIGURATION
# ============================================================================

processing:
  # Primary model for all operations
  model: "gpt-4o"
  temperature: 0.3
  max_tokens: 50000
  max_response_words: 1500
  
  # XML structure processing
  xml_processing:
    enabled: true
    validate_structure: true
    
  # Response strategy based on SOP coverage
  coverage_thresholds:
    high_confidence: 0.7      # Full answer with citations
    medium_confidence: 0.4    # Answer with caveat about partial coverage
    low_confidence: 0.4       # Trigger escape hatch

# ============================================================================
# DEFAULT/FALLBACK MODELS - Used when specific configs are missing
# ============================================================================

defaults:
  # Primary model for most operations
  primary_model: "gpt-4o"
  # Lightweight model for simple tasks
  lightweight_model: "gpt-4o-mini" 
  # Default temperature for creative responses
  creative_temperature: 0.6
  # Default temperature for analytical responses
  analytical_temperature: 0.3

# ============================================================================
# ESCAPE HATCH CONFIGURATION
# ============================================================================

escape_hatch:
  # When to trigger escape hatch responses
  trigger_threshold: 0.4
  
  # Message configuration
  message_template: |
    The Playbook does not explicitly provide guidance for {topic}.
    
    {partial_info}
    
    üìù This appears to be a gap in our Playbook. Please leave feedback so we can add appropriate guidance for this topic.
  
  # Always show partial information even with low confidence
  show_partial_info: true
  
  # Request feedback on gaps
  request_feedback: true
  
  # Feedback prompt text
  feedback_prompt: "üìù Please leave feedback about this gap so we can improve our Playbook."



# ============================================================================
# SOP DIRECTORY MANAGEMENT - Auto-updating SOP overview
# ============================================================================

sop_directory:
  # Automatically update the SOP directory when SOPs change
  auto_generate: true
  
  # File location for the SOP directory
  directory_file: "sop-directory.md"
  
  # What to include in the directory
  include_topics: true
  include_relationships: true
  include_summaries: true
  include_keywords: false  # As requested
  
  # Allow editing in admin center
  editable_in_admin: true
  
  # Update triggers
  update_on_sop_create: true
  update_on_sop_edit: true
  update_on_sop_delete: true

# ============================================================================
# CONTEXT MANAGEMENT - Handle conversation history and token limits
# ============================================================================

context_management:
  # Conversation history settings
  conversation_history:
    max_messages: 6  # Keep last 6 message pairs in context
    summarize_older: true  # Summarize older messages when needed
    summary_max_words: 100  # Max words for conversation summaries
    
  # Token limit management
  token_limits:
    soft_limit: 6000  # Start optimizing context at this point
    hard_limit: 8000  # Maximum tokens allowed
    warning_threshold: 7000  # Warn user when approaching limit
    
  # What to do when hitting context limits
  overflow_strategy:
    method: "chain_of_thought_with_summarization"
    priority_order: ["current_query", "sop_content", "conversation_summary"]
    
  # Progressive context expansion for comprehensive mode
  progressive_expansion:
    enabled: true
    initial_sops: 3
    max_expansion_sops: 7
    expansion_threshold: 0.7  # Confidence threshold for expanding

# ============================================================================
# FEEDBACK AND IMPROVEMENT - User feedback handling
# ============================================================================

feedback_system:
  # Auto-trigger comprehensive mode on negative feedback
  auto_comprehensive_on_thumbs_down: true
  
  # Confidence thresholds
  confidence_thresholds:
    high: 0.8  # High confidence responses
    medium: 0.6  # Medium confidence - might need improvement
    low: 0.4  # Low confidence - suggest comprehensive mode
    
  # Auto-suggest comprehensive mode for low confidence
  auto_suggest_comprehensive: true

# ============================================================================
# SOP SELECTION AND RETRIEVAL
# ============================================================================

sop_selection:
  # How to select SOPs for a query
  model: "gpt-4o"
  temperature: 0.2
  selection_method: "xml_structured"
  min_confidence: 0.3  # Lower threshold to catch partial matches
  max_sops: 3
  
  # Coverage assessment
  coverage_analysis:
    enabled: true
    gap_detection: true
    confidence_calibration: true

# ============================================================================
# SESSION AND SUMMARY MANAGEMENT
# ============================================================================

session_management:
  # Model for generating session summaries
  summary_model: "gpt-4o-mini"
  summary_temperature: 0.3
  summary_max_tokens: 20

# ============================================================================
# FEATURE FLAGS - Enable/disable specific features
# ============================================================================

features:
  enable_xml_processing: true
  enable_sop_directory: true
  enable_escape_hatch: true
  enable_inline_citations: true
  enable_confidence_scoring: true
  enable_coverage_analysis: true
  enable_conversation_summaries: true

# ============================================================================
# DEBUGGING AND MONITORING
# ============================================================================

debug:
  log_response_modes: true
  log_context_usage: true
  log_chain_of_thought_steps: true
  log_sop_selection_reasoning: true
  save_comprehensive_triggers: true

# ============================================================================
# ENVIRONMENT-SPECIFIC OVERRIDES
# ============================================================================

environments:
  development:
    debug:
      log_xml_processing: true
      log_context_usage: true
      log_coverage_analysis: true
    processing:
      temperature: 0.4  # Slightly higher for testing variety
    prompts_config:
      active_prompt_set: "default"
        
  production:
    debug:
      log_xml_processing: false
      log_context_usage: false
      log_coverage_analysis: false
    context_management:
      token_limits:
        hard_limit: 7500  # Slightly more conservative
    escape_hatch:
      trigger_threshold: 0.5  # Higher threshold for production
    prompts_config:
      active_prompt_set: "default"
        
  testing:
    processing:
      model: "gpt-4o-mini"  # Use cheaper model for tests
      max_response_words: 500  # Shorter for faster tests
    sop_selection:
      model: "gpt-4o-mini"
    escape_hatch:
      trigger_threshold: 0.3  # Lower threshold to test escape scenarios
    prompts_config:
      active_prompt_set: "default"